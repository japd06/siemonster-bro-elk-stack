# READ ME FIRST

I was recently tasked with feeding the collection logs generated by Bro into a SIEMonster cluster. As I could not find documentation on the subject myself, I'm just publishing my results and progress. This might will probably be useful to people running the ELK stack in general, rather than just those who have deployed SIEMonster.

For anyone checking progress:

This has been successfully transmitting log data from Bro (as part of Security Onion), by using Filebeat to transmit the logs to Logstash. Transformations are done in Logstash, and the data gets inserted into Elasticsearch.

I have been having good luck with this, but if you follow my footsteps, back up EVERYTHING first. I offer no warranties, guarantees, or anything else.

If you're interested in monitoring progress, I'd suggest you check often over the next couple weeks, I'll try to update this on a regular basis.

#### Document History
    Initial publication date: Aug 29, 2017



## CURRENT PROGRESS

With a few exceptions, most of the logs generated by Bro are sent into Elasticsearch indexes.

The exceptions (logs not collected by the filebeat prospector) are as follows:

- `communication.log`
- `stats.log`
- `stderr.log`
- `stdout.log`

These logs are stored in their own, individual indexes, named after their log type (`conn.log` gets stored in the `bro-conn-` index:

- `conn.log`
- `dhcp.log`
- `dns.log`
- `files.log`
- `http.log`
- `http-eth-*.log`
- `notice.log`
- `ssl.log`
- `ssh.log`
- `weird.log`
- `x509.log`

Filebeat will send any other logs it finds to logstash, which will store them all in a single Elasticsearch index called called `bro-`.


## GETTING STARTED

The first step is to replace the logstash configuration files supplied by Kustodian with the replacement from my repository.

Many of the files are identical to those originally supplied, I just changed the numeric prefix from 2 numbers to 4 numbers.

Many of the additional files were written by Justin Henderson, and referenced on the Security Onion blog. I alerted his orginal .conf files by deleing the optional tag he generated and replacing that with a custom field.

I altered SIEMonsters original files in the following ways:

**0000-inputs.conf**

Added a listener for Bro data on port 3524

**9999-ouputs.conf**

Added an output to the general Bro index (which is currently commented out)

My contribution were following files:

**1010-bro-tag-by-source.conf**

For some reason, Justin's files weren't properly detecting the incoming filebeat data. I took a hammer to the problem and set the data `type` by inspecting the incoming file name.

**1120_preprocess_bro_x509.conf**

Parses the x509 logs and stores them in their own index. I'll be doing further parsing later on, but at least they're being recognized.

**6001_bro_post_process.conf**

After a bro log has been successfully processed (meaning, message data has been separated and stored in individual fields), we remove the message field algother.

**6002_bro_clean_tags.conf**

Some garbage was sneaking in, which I couldn't figure out the source of, resulting in every bro event being received by filebeat being given two tags, `beats_input_codec_json_applied` and `_jsonparsefailure`. 

Because I haven't figured out where the beats codec tag is getting applied, and I haven't noted any actual parsing failures when comparing the data received by Logstash and what was sent by filebeat, this config file simply deletes those tags. 

**9900-bro_output.conf**

This stores the identified logs that we have working parsers for in their own indexes. Any other bro data gets sent to a single `bro-` index.

### NOTE
If you want to Logstash to output ALL of your bro data into a single Elasticsearch Index, just move `9900-bro-output.conf` outside of the config directory, and uncomment lines 48-53 in `9999-outputs.conf`

## GETTING STARTED

Files in this repository:

    siemonster-instances
       proteus
         logstash-container
            /config-dir/many-replacement-files
    
       capricorn
         411-volume-container
           /data/config.php

    security-onion
       /etc/filebeat/filebeat.yml
    
This shouldn't need to be said, but I will anyways: **Backup ALL of your original files before replacing them.**

#### Proteus / Logstash: 

SSH to Proteus, then connect to the docker container running Logstash inside of it. Move all of the original *.conf files out of the /config-dir directory, and copy the replacement files from this repository into their place.

You will edit `0000-inputs.conf` and change to the path to Logstash's SSL certificate and key whereever it is referred to. 

Once that's complete, login to Makara and restart the Logstash container in order to finish configuring the new logstash pipeline..

#### Capricorn / Alerts 411

SSH to Capricorn, then connect to the alerts-411-volume instance, and replace `/data/config.php` with the `/data/config.php` from this repository. This adds entries to the select menu in SIEMonsters alerts interface, reflecting the new indexes that Logstash will be sending data into.

#### SecurityOnion / Filebeat configuration file for Bro

Assuming you have Security Onion running and configured to store data in the `/nsm/bro/logs/current`, you will need to:

- Copy the logstash certificate onto the Security Onion machine (in my filebeat configuration file, it is referenced as: `/etc/pki/tls/certs/logstash-forwarder.crt`
- The certificate should be owned by `root` and be given `600` permissions
- Install **filebeat** per the instructions provided by SIEMonster or Elastic Co (TODO: Links to come)
- Replace the `/etc/filebeat/filebeat.yml` configuration file with the one from this repository.

**Changes you might need to make to filebeat.yml:**

Line 15 - path to the bro logs (default: `/nsm/bro/logs/current/`; update only if you're storing your bro data in a different directory.

Line 281 - IP address of your Proteus instance (where Logstash is running, and where Filebeat should send its data).

Line 304 - Path to the SSL certificate for your Logstash instance.

Once you've made those changes and restart the filebeat service, all of the logs compiled by Bro should begin getting transferred to Logstash for processing.

## What Now?

If everything went according to plan, you can now create SIEMonster alerts based on the incoming bro data. Log into SIEMonster, go into the Alerts screen, create a new Search against Elasticsearch (ES) data, and you'll be able to select from the new Bro indexes you created.

## Credits:

Based on the work of many others, including:

[Elastic Co](https://www.elastic.co)

[Kustodian](https://kustodian.com), the developers of [SIEMonster](https://siemonster.com)

[Security Onion](https://securityonion.net) who had already done most of the groundwork in feeding [Bro](https://www.bro.org) data into the ELK stack.


## TODO:

#### Kibana
The biggest item on the TO-DO list it to be able to display the collected data in Kibana.

As I have primarily been focused on the Alerts 411 system used by SIEMonster, I haven't 
had the time or opportunity to figure out how to inspect the data in Kibana.


#### General Cleanup
You'll note that in each logstash `bro-` configuration file, there is a step at the end which appends a `logstash-step` field to the end of the data. That's only there for current troubleshooting purposes, and can be safely removed/commented out.